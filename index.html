<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zongyu Lin</title>

  <meta name="author" content="Zongyu Lin">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</heads>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zongyu (Johnson) Lin「林宗裕」</name>
              </p>
              <p>I am a CS Ph.D Student at UCLA, co-advised by Prof. Yizhou Sun and Prof. Kaiwei Chang. Luckily, I have worked with <a href="https//kimiyoung.github.io/">Prof. Zhilin Yang</a>, <a href="http://fi.ee.tsinghua.edu.cn/~liyong/">Prof. Yong Li</a>, <a href="http://www.cs.umd.edu/~hjs/">Prof. Hanan Samet</a> and <a href="https://infolab.usc.edu/Shahabi/index.html">Prof. Cyrus Shahabi</a>. Before coming to UCLA, I have spent almost a year in Moonshot.AI, as a LLM researcher. I was one of the major contributor of training large language models with extremely long context, achieving the state-of-the-art performance on many long context tasks compared with GPT4 and Claude2, and also participated in visual generation project. </p>
              <p>My research interest lies broadly in natural language processing and general machine learning. I have done some work including self-training, instruction finetuning and zero-shot task generalization of LLMs. Most Recently, I am interested in (1) improving the self-evolution of large language models as well as (2) exploring scalable architectures and recipes for multi-modal generation. Feel free to contact me for casual chat or discussion if you are also interested in these topics.
              </p>
              <p>
                Email: lzyxx17 [at] gmail.com
              </p>
              <p style="text-align:left">
                <!--<a href="lin-zy17@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp-->
                <!--<a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a>-->
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=4ahRAd4AAAAJ">Google Scholar</a> &nbsp
                <!--<a href="https://www.linkedin.com/in/%E5%AE%97%E8%A3%95-%E6%9E%97-0020b81b9/">Linkedin</a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:70%;max-width:70%">
              <a href="images/zongyulin_2.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/zongyulin_2circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Topic</heading>
              <p>My research interest lies broadly in natural language processing and general machine learning. Most Recently, I am interested in 
                <p>(1) improving the self-evolution of large language models;
                <p>(2) exploring scalable architectures and recipes for multi-modal generation;
                <p>(3) improve better physics understanding for vision / embodied language models
                <!--Representative papers are <span class="highlight">highlighted</span>.-->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px">
            <heading>Recent Work</heading>
            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/UD-2.png' width="160"></div>
                  <img src='images/UD-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"> -->
                  <papertitle>A Universal Discriminator for Zero-Shot Generalization</papertitle>
                <!-- </a> -->
                <br>
                Haike Xu,
                <strong>Zongyu Lin</strong>,
                Jing Zhou,
                Yanan Zheng, Zhilin Yang
                 <br>
                <em>ACL Long Paper</em>, 2023
                <br>
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">paper</a> -->
                <p></p>
                <p>
                  Generative modeling has been the dominant approach for large-scale pretraining and zero-shot generalization. In this work, we challenge this convention by showing that discriminative approaches perform substantially better than generative ones on a large number of NLP tasks. Technically, we train a single discriminator to predict whether a text sample comes from the true data distribution, similar to GANs. Since many NLP tasks can be formulated as selecting from a few options, we use this discriminator to predict the option with the highest probability. This simple formulation achieves state-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by 16.0%, 7.8%, and 11.5% respectively on different scales.
                  Meanwhile, our approach requires minimal prompting efforts, which largely improves robustness and is essential for real-world applications.
                </p>
              </td>
            </tr>


             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/improvet0-2.png' width="160"></div>
                  <img src='images/improvet0-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"> -->
                  <papertitle>NOT ALL TASKS ARE BORN EQUAL: UNDERSTANDING ZERO-SHOT GENERALIZATION</papertitle>
                <!-- </a> -->
                <br>
                Jing Zhou,
                <strong>Zongyu Lin</strong>,
                Yanan Zheng, Zhilin Yang
                 <br>
                <em>ICLR Spotlight</em>, 2023
                <br>
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">paper</a> -->
                <p></p>
                <p>
                  Recent work has achieved remarkable zero-shot performance with multi-task prompted pretraining, but little has been understood. For the first time, we show
                  that training on a small number of key tasks beats using all the training tasks,
                  while removing these key tasks substantially hurts performance. We also find that
                  these key tasks are mostly question answering (QA) tasks. We design a shuffle
                  experiment to further show that training on these QA tasks leads to better cross-task
                  generalization in multi-task learning under various training/test task splits. These
                  novel findings combined deepen our understanding about zero-generalization—
                  training on certain tasks such as QA encodes general knowledge transferable to a
                  wide range of tasks, which explains the improved zero-shot performance in recent
                  progress. In addition, to automate this procedure, we devise a method to identify
                  and upsample key training tasks without observing the test tasks based on cross
                  validation. Empirically, our approach achieves improved results across various
                  model scales and tasks.
                </p>
              </td>
            </tr>

            <!-- <heading>Publications</heading> -->
             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/sent-2.png' width="160"></div>
                  <img src='images/sent-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"> -->
                  <papertitle>Learning to Detect Noisy Labels Using Model-Based Features</papertitle>
                <!-- </a> -->
                <br>
                Zhihao Wang*,
                <strong>Zongyu Lin*</strong>,
                Peiqi Liu, Guidong Zheng, Junjie Wen, Xianxin Chen, Yujun Chen, Zhilin Yang
                (* First Co-Authors)
                <br>
                <em>Findings of EMNLP</em>, 2023
                <br>
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">paper</a> -->
                <p></p>
                <p>
                  Label noise is ubiquitous in various machine learning scenarios such as self-labeling with model predictions and erroneous data annotation. Many existing approaches are based on heuristics such as sample losses, which might not be flexible enough to achieve optimal solutions. Meta learning based methods address this issue by learning a data selection function, but can be hard to optimize. In light of these pros and cons, we propose SENT (Selection-Enhanced Noisy label Training) that does not rely on meta learning while having the flexibility of being data-driven. SENT transfers the noise distribution to a clean set and trains a model to distinguish noisy labels from clean ones using model-based features. Empirically, on a wide range of tasks including text classification and speech recognition, SENT improves performance over strong baselines under the settings of self-training and label corruption.
                </p>
              </td>
            </tr>
            <td style="padding:20px">
              <heading>Publications</heading>
             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/sent-2.png' width="160"></div>
                  <img src='images/sent-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"> -->
                  <papertitle>Learning to Detect Noisy Labels Using Model-Based Features</papertitle>
                <!-- </a> -->
                <br>
                <strong>Zongyu Lin*</strong>,
                Zhihao Wang*
                Peiqi Liu, Guidong Zheng, Junjie Wen, Xianxin Chen, Yujun Chen, Zhilin Yang
                (* First Co-Authors)
                <br>
                <em>Findings of EMNLP</em>, 2022 (To Appear)
                <br>
                <!-- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">paper</a> -->
                <p></p>
                <p>
                  Label noise is ubiquitous in various machine learning scenarios such as self-labeling with model predictions and erroneous data annotation. Many existing approaches are based on heuristics such as sample losses, which might not be flexible enough to achieve optimal solutions. Meta learning based methods address this issue by learning a data selection function, but can be hard to optimize. In light of these pros and cons, we propose SENT (Selection-Enhanced Noisy label Training) that does not rely on meta learning while having the flexibility of being data-driven. SENT transfers the noise distribution to a clean set and trains a model to distinguish noisy labels from clean ones using model-based features. Empirically, on a wide range of tasks including text classification and speech recognition, SENT improves performance over strong baselines under the settings of self-training and label corruption.
                </p>
              </td>
            </tr>
             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/hagen-1.png' width="160"></div>
                  <img src='images/hagen-2.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">
                  <papertitle>Hagen: Homophily-aware graph convolutional recurrent network for crime forecasting</papertitle>
                </a>
                <br>
                <strong>Zongyu Lin*</strong>,
                Chenyu Wang*,
                Guozhen Zhang, 
                Xiaochen Yang, 
                Jiao Sun, Mingxuan Yue, Cyrus Shahabi
                (* First Co-Authors)
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2022
                <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338">paper</a>
                <p></p>
                <p>
                  We propose an end-to-end graph convolutional recurrent network called HAGEN with several novel designs for crime prediction. Specifically, our framework could jointly capture the crime correlation between regions and the temporal crime dynamics by combining an adaptive region graph learning module with the Diffusion Convolution Gated Recurrent Unit (DCGRU). Based on the homophily assumption of GNN (i.e., graph convolution works better where neighboring nodes share the same label), we propose a homophily-aware constraint to regularize the optimization of the region graph so that neighboring region nodes on the learned graph share similar crime patterns.
                </p>
              </td>
            </tr>
             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/vehicle-2.png' width="160"></div>
                  <img src='images/vehicle-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3474717.3483987">
                  <papertitle>Vehicle Trajectory Recovery on Road Network Based on Traffic Camera Video Data</papertitle>
                </a>
                <br>
                <strong>Zongyu Lin</strong>,
                Guozhen Zhang, 
                Zhiqun He, 
                Jie Feng, 
                Wei Wu, 
                <a href="http://fi.ee.tsinghua.edu.cn/~liyong/">Yong Li</a>
                <br>
                <em>Proceedings of the 29th International Conference on Advances in Geographic Information Systems</em>, 2021
                <br>
                <a href="https://dl.acm.org/doi/pdf/10.1145/3411807">paper</a>
                <p></p>
                <p>
                  We propose a general system to recover vehicle trajectories at the level of the road intersection, where a novel iterative framework is developed to combine both vehicle clustering and trajectory recovery tasks.
                </p>
              </td>
            </tr>
             <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
               <td style="padding:20px;width:25%;vertical-align:middle">
                 <div class="one">
                   <div class="two" id='dualrefl_image'>
                     <img src='images/hw_before.png' width="160"></div>
                   <img src='images/hw_after.png' width="160">
                 </div>
                 <script type="text/javascript">
                   function dualrefl_start() {
                     document.getElementById('dualrefl_image').style.opacity = "1";
                   }

                   function dualrefl_stop() {
                     document.getElementById('dualrefl_image').style.opacity = "0";
                   }
                   dualrefl_stop()
                 </script>
               </td>
               <td style="padding:20px;width:75%;vertical-align:middle">
                 <a href="https://dl.acm.org/doi/abs/10.1145/3432229">
                   <papertitle>HealthWalks: Sensing Fine-grained Individual Health Condition via Mobility Data</papertitle>
                 </a>
                 <br>
                 <strong>Zongyu Lin</strong>,
                 Shiqing Lyu,
                 <a href="http://sniklaus.com/welcome">Hancheng Cao</a>,
                 Yuqiong Wei,
                 <a href="https://www.cse.ust.hk/~panhui/publications.html">Pan Hui</a>,
                 <a href="http://www.cs.umd.edu/~hjs/">Hanan Samet</a>,
                 <a href="http://fi.ee.tsinghua.edu.cn/~liyong/">Yong Li</a>
                 <br>
                 <em>In ACM International Joint Conference on Pervasive and Ubiquitous Computing (UBICOMP)</em>, 2020
                 <br>
                 <!-- <a href="http://sniklaus.com/dualref">project page</a> / -->
                 <a href="https://dl.acm.org/doi/abs/10.1145/3432229">paper</a>
                 <p></p>
                 <p>
                   We propose a DFA-based model which can generate interpretable features automatically from raw mobility data for fine-grained health sensing.
               </td>
             </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lssr_image'>
                  <img src='images/sume_after.png' width="160"></div>
                <img src='images/sume_before.png' width="160">
              </div>
              <script type="text/javascript">
                function lssr_start() {
                  document.getElementById('lssr_image').style.opacity = "1";
                }

                function lssr_stop() {
                  document.getElementById('lssr_image').style.opacity = "0";
                }
                lssr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3411807">
                <papertitle>SUME: Semantic-enhanced Urban Mobility Network Embedding for User Demographic Inference</papertitle>
              </a>
              <br>
              <a href="http://fenglixu.com">Fengli Xu*</a>,
              <strong>Zongyu Lin*</strong>,
              Tong Xia,
              Diansheng Guo,
              <a href="http://fi.ee.tsinghua.edu.cn/~liyong/">Yong Li</a>
              (* Equal Contributions)
              <br>
              <em>In ACM International Joint Conference on Pervasive and Ubiquitous Computing (UBICOMP)</em>, 2020
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3411807">paper</a>
              <p></p>
              <p>
                We propose a semantic-enhanced urban mobility embedding model for user profiling, and reveal meaningful patterns in all spatial, temporal and urban structure domains.
              </p>
            </td>
          </tr>

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nlt_image'>
                  <!--
                  <video  width=100% height=100% muted autoplay loop>
                <source src="images/cf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div>-->
                <img src='images/cf_before.png' width="160">
                </div>
                <img src='images/cf_after.png' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!--<a href="http://nlt.csail.mit.edu/">
                <papertitle>CrimeForecaster: Crime Prediction by Exploiting the Neighborhoods’ Spatiotemporal Dependencies</papertitle>
              </a>-->
              <papertitle>CrimeForecaster: Crime Prediction by Exploiting the Neighborhoods’ Spatiotemporal Dependencies</papertitle>
              <br>
              Jiao Sun,
              Mingxuan Yue,
              <!--<a href="https://sunjiao123sun.github.io/#publication">Jiao Sun</a>,-->
              <strong>Zongyu Lin</strong>,
              Xiaochen Yang,
              Gabe Kahn,
              Luciano Nocera,
              <a href="http://billf.mit.edu/">Cyrus Shahabi</a>
              <br>
              <em>The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD) </em>, 2020 (To appear)
              <br>
              <!--<a href="http://nlt.csail.mit.edu/">project page</a> /
              <a href="https://arxiv.org/abs/2008.03806">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=OGEnCWZihHE">video</a>-->
              <p></p>
              <p>We introduce a new end-to-end spatiotemporal learning framework dubbed CrimeForecaster that: 1) represents the geographical extents of neighborhoods and their correlations in a graph; 2) uses graph convolution to predict crimes.</p>
            </td>
          </tr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
                <strong>LLM Researcher</strong>, Moonshot.AI 2023
              <p>
                <strong>Quant Researcher Intern</strong>, Ubiquant, Top Hedge Fund in China. 2022
              <p>  <strong>Research Intern</strong>, Sensetime, China, 2021
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Awards</heading>
                <p>
                  <strong>Comprehensive Outstanding Scholarship(~10/280)</strong>, Tsinghua University. 2020
                <p>  <strong>Excellent Technology Innovation Scholarship</strong>, Tsinghua University. 2020
                <p>  <strong>First Prize in Software Design Contest</strong>, Department of Electronic Enginnering, Tsinghua University. 2018
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Hobbies</heading>
                <p>
                  <strong>Sports!</strong> I really enjoy playing ballgames like football and tennis. I am a big fan of Lionel Messi, Rafael Nadal and Stephen Curry! Also, I love running, swimming and hiking.
                <!--<p>  <strong>Ballroom Dancing</strong>, Tsinghua University. 2020-->

                </p>
              </td>
            </tr>
          </tbody></table>
<p> Updated at Dec.2023. Thanks <a href="https://jonbarron.info">Jon Barron</a> for this concise and beautiful template.
<!--
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
